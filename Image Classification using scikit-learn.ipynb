{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZA2wl7uJxmGR"
   },
   "source": [
    "# Image Classification with SVM, MLP, KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference: https://github.com/whimian/SVM-Image-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1603696016294,
     "user": {
      "displayName": "怡瑄林",
      "photoUrl": "",
      "userId": "14678193008920519702"
     },
     "user_tz": -480
    },
    "id": "eIFE0W2-utHT"
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 42587,
     "status": "ok",
     "timestamp": 1603688341833,
     "user": {
      "displayName": "怡瑄林",
      "photoUrl": "",
      "userId": "14678193008920519702"
     },
     "user_tz": -480
    },
    "id": "C2m0upRhxmGS"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "from sklearn import svm, metrics, datasets\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFzw6vVqxmGU"
   },
   "source": [
    "### Load images in structured directory like it's sklearn sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 42589,
     "status": "ok",
     "timestamp": 1603688341839,
     "user": {
      "displayName": "怡瑄林",
      "photoUrl": "",
      "userId": "14678193008920519702"
     },
     "user_tz": -480
    },
    "id": "GqXJk2MHxmGV"
   },
   "outputs": [],
   "source": [
    "def load_image_files(container_path, dimension=(64, 64)):\n",
    "    \"\"\"\n",
    "    Load image files with categories as subfolder names \n",
    "    which performs like scikit-learn sample dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_path : string or unicode\n",
    "        Path to the main folder holding one subfolder per category\n",
    "    dimension : tuple\n",
    "        size to which image are adjusted to\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Bunch\n",
    "    \"\"\"\n",
    "    image_dir = Path(container_path)\n",
    "    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n",
    "    categories = [fo.name for fo in folders]\n",
    "\n",
    "    descr = \"A image classification dataset\"\n",
    "    images = []\n",
    "    flat_data = []\n",
    "    target = []\n",
    "    for i, direc in enumerate(folders):\n",
    "        for file in direc.iterdir():\n",
    "            img = imread(file)\n",
    "            img_resized = resize(img, dimension, anti_aliasing=True, mode='reflect')\n",
    "            flat_data.append(img_resized.flatten()) \n",
    "            images.append(img_resized)\n",
    "            target.append(i)\n",
    "    flat_data = np.array(flat_data)\n",
    "    target = np.array(target)\n",
    "    images = np.array(images)\n",
    "\n",
    "    return Bunch(data=flat_data,\n",
    "                 target=target,\n",
    "                 target_names=categories,\n",
    "                 images=images,\n",
    "                 DESCR=descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3409792,
     "status": "error",
     "timestamp": 1603702483488,
     "user": {
      "displayName": "怡瑄林",
      "photoUrl": "",
      "userId": "14678193008920519702"
     },
     "user_tz": -480
    },
    "id": "WSwiECTjxmGX",
    "outputId": "e017616f-abab-43a5-b4ad-ef454b7e6919",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_dataset = load_image_files(\"dataset/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7fjhJ1WxmGa"
   },
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "aborted",
     "timestamp": 1603694260316,
     "user": {
      "displayName": "怡瑄林",
      "photoUrl": "",
      "userId": "14678193008920519702"
     },
     "user_tz": -480
    },
    "id": "9tb4AszMxmGa"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_dataset.data, image_dataset.target, test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BL7hy7ufxmGc"
   },
   "source": [
    "### Train data with parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "aborted",
     "timestamp": 1603694260317,
     "user": {
      "displayName": "怡瑄林",
      "photoUrl": "",
      "userId": "14678193008920519702"
     },
     "user_tz": -480
    },
    "id": "SxpOWOj_xmGd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'C': [1, 10, 100, 1000], 'kernel': ['linear']}, {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, param_grid)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "0.586 (+/-0.014) for {'C': 1, 'kernel': 'linear'}\n",
      "0.586 (+/-0.014) for {'C': 10, 'kernel': 'linear'}\n",
      "0.586 (+/-0.014) for {'C': 100, 'kernel': 'linear'}\n",
      "0.586 (+/-0.014) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.679 (+/-0.051) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.627 (+/-0.057) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.673 (+/-0.025) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.658 (+/-0.059) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.666 (+/-0.046) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.629 (+/-0.008) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.666 (+/-0.046) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.623 (+/-0.004) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Best paramete set\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "print('\\n')\n",
    "\n",
    "# All results\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.679\n"
     ]
    }
   ],
   "source": [
    "print('best score: %0.3f' %clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NUAWMcyxmGf"
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "aborted",
     "timestamp": 1603694260317,
     "user": {
      "displayName": "怡瑄林",
      "photoUrl": "",
      "userId": "14678193008920519702"
     },
     "user_tz": -480
    },
    "id": "pofP8_agxmGf"
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IS2TjGxmxmGh"
   },
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "aborted",
     "timestamp": 1603694260319,
     "user": {
      "displayName": "怡瑄林",
      "photoUrl": "",
      "userId": "14678193008920519702"
     },
     "user_tz": -480
    },
    "id": "WdT2VwBDxmGi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for - \n",
      "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False),\n",
      "       fit_params=None, iid='warn', n_jobs=None,\n",
      "       param_grid=[{'C': [1, 10, 100, 1000], 'kernel': ['linear']}, {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.78      0.73       161\n",
      "           1       0.69      0.57      0.63       138\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       299\n",
      "   macro avg       0.69      0.68      0.68       299\n",
      "weighted avg       0.69      0.69      0.68       299\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for - \\n{}:\\n{}\\n\".format(\n",
    "    clf, metrics.classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集:  0.8949640287769784\n",
      "測試集:  0.6387959866220736\n"
     ]
    }
   ],
   "source": [
    "# 預測成功的比例\n",
    "print('訓練集: ',clf.score(X_train,y_train))\n",
    "print('測試集: ',clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference: https://www.kaggle.com/pandaqc/mlp-with-sickitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats, integrate\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import Bunch\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from pathlib import Path\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_files(container_path, dimension=(64, 64)):\n",
    "    image_dir = Path(container_path)\n",
    "    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n",
    "    categories = [fo.name for fo in folders]\n",
    "\n",
    "    descr = \"A image classification dataset\"\n",
    "    images = []\n",
    "    flat_data = []\n",
    "    target = []\n",
    "    for i, direc in enumerate(folders):\n",
    "        for file in direc.iterdir():\n",
    "            img = imread(file)\n",
    "            img_resized = resize(img, dimension, anti_aliasing=True, mode='reflect')\n",
    "            flat_data.append(img_resized.flatten()) \n",
    "            images.append(img_resized)\n",
    "            target.append(i)\n",
    "    flat_data = np.array(flat_data)\n",
    "    target = np.array(target)\n",
    "    images = np.array(images)\n",
    "\n",
    "    return Bunch(data=flat_data,\n",
    "                 target=target,\n",
    "                 target_names=categories,\n",
    "                 images=images,\n",
    "                 DESCR=descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = load_image_files(\"dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_dataset.data, image_dataset.target, test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (695, 12288) y_train shape: (695,)\n",
      "X_val shape: (299, 12288) y_val shape: (299,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape, 'y_train shape:', y_train.shape)\n",
    "print('X_val shape:', X_test.shape, 'y_val shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68151234\n",
      "Iteration 2, loss = 0.66159792\n",
      "Iteration 3, loss = 0.64534279\n",
      "Iteration 4, loss = 0.63617046\n",
      "Iteration 5, loss = 0.63410727\n",
      "Iteration 6, loss = 0.62022041\n",
      "Iteration 7, loss = 0.60828458\n",
      "Iteration 8, loss = 0.60651048\n",
      "Iteration 9, loss = 0.59605962\n",
      "Iteration 10, loss = 0.59096369\n",
      "Iteration 11, loss = 0.58464550\n",
      "Iteration 12, loss = 0.57789966\n",
      "Iteration 13, loss = 0.57607201\n",
      "Iteration 14, loss = 0.56831476\n",
      "Iteration 15, loss = 0.56305529\n",
      "Iteration 16, loss = 0.55951831\n",
      "Iteration 17, loss = 0.55531892\n",
      "Iteration 18, loss = 0.55625251\n",
      "Iteration 19, loss = 0.54843815\n",
      "Iteration 20, loss = 0.54611627\n",
      "Iteration 21, loss = 0.54189821\n",
      "Iteration 22, loss = 0.53590090\n",
      "Iteration 23, loss = 0.53557412\n",
      "Iteration 24, loss = 0.52942558\n",
      "Iteration 25, loss = 0.52738052\n",
      "Iteration 26, loss = 0.52361644\n",
      "Iteration 27, loss = 0.51902282\n",
      "Iteration 28, loss = 0.51682205\n",
      "Iteration 29, loss = 0.51497357\n",
      "Iteration 30, loss = 0.51422712\n",
      "Iteration 31, loss = 0.50749234\n",
      "Iteration 32, loss = 0.50502269\n",
      "Iteration 33, loss = 0.50282566\n",
      "Iteration 34, loss = 0.49843649\n",
      "Iteration 35, loss = 0.49923541\n",
      "Iteration 36, loss = 0.49284113\n",
      "Iteration 37, loss = 0.49492107\n",
      "Iteration 38, loss = 0.49145904\n",
      "Iteration 39, loss = 0.48537068\n",
      "Iteration 40, loss = 0.48724389\n",
      "Iteration 41, loss = 0.48121911\n",
      "Iteration 42, loss = 0.47665956\n",
      "Iteration 43, loss = 0.47449883\n",
      "Iteration 44, loss = 0.47138863\n",
      "Iteration 45, loss = 0.46974733\n",
      "Iteration 46, loss = 0.46652444\n",
      "Iteration 47, loss = 0.46606022\n",
      "Iteration 48, loss = 0.46133458\n",
      "Iteration 49, loss = 0.45857861\n",
      "Iteration 50, loss = 0.45916099\n",
      "Iteration 51, loss = 0.45616469\n",
      "Iteration 52, loss = 0.45519614\n",
      "Iteration 53, loss = 0.45011580\n",
      "Iteration 54, loss = 0.44890255\n",
      "Iteration 55, loss = 0.44609665\n",
      "Iteration 56, loss = 0.44391933\n",
      "Iteration 57, loss = 0.44605538\n",
      "Iteration 58, loss = 0.43810210\n",
      "Iteration 59, loss = 0.43925890\n",
      "Iteration 60, loss = 0.43366538\n",
      "Iteration 61, loss = 0.43036568\n",
      "Iteration 62, loss = 0.43327922\n",
      "Iteration 63, loss = 0.42748438\n",
      "Iteration 64, loss = 0.42673619\n",
      "Iteration 65, loss = 0.42344640\n",
      "Iteration 66, loss = 0.42459310\n",
      "Iteration 67, loss = 0.42031074\n",
      "Iteration 68, loss = 0.42018256\n",
      "Iteration 69, loss = 0.41645444\n",
      "Iteration 70, loss = 0.41143873\n",
      "Iteration 71, loss = 0.40871290\n",
      "Iteration 72, loss = 0.40955804\n",
      "Iteration 73, loss = 0.40778724\n",
      "Iteration 74, loss = 0.40292368\n",
      "Iteration 75, loss = 0.40132003\n",
      "Iteration 76, loss = 0.40125087\n",
      "Iteration 77, loss = 0.40218770\n",
      "Iteration 78, loss = 0.39587286\n",
      "Iteration 79, loss = 0.39376212\n",
      "Iteration 80, loss = 0.39250687\n",
      "Iteration 81, loss = 0.38813011\n",
      "Iteration 82, loss = 0.38508783\n",
      "Iteration 83, loss = 0.38719934\n",
      "Iteration 84, loss = 0.38143319\n",
      "Iteration 85, loss = 0.38562813\n",
      "Iteration 86, loss = 0.38380148\n",
      "Iteration 87, loss = 0.37540594\n",
      "Iteration 88, loss = 0.37607112\n",
      "Iteration 89, loss = 0.37555890\n",
      "Iteration 90, loss = 0.37000278\n",
      "Iteration 91, loss = 0.36973190\n",
      "Iteration 92, loss = 0.36565041\n",
      "Iteration 93, loss = 0.36383428\n",
      "Iteration 94, loss = 0.36396920\n",
      "Iteration 95, loss = 0.36079713\n",
      "Iteration 96, loss = 0.35989570\n",
      "Iteration 97, loss = 0.35649377\n",
      "Iteration 98, loss = 0.35599382\n",
      "Iteration 99, loss = 0.35324288\n",
      "Iteration 100, loss = 0.35003555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50), (100,)], 'activation': ['tanh', 'relu'], 'solver': ['sgd', 'adam', 'lbfgs'], 'alpha': [0.0001, 0.05], 'learning_rate': ['constant', 'adaptive']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instanciate the MLP classifier\n",
    "mlp = MLPClassifier(max_iter=100,verbose=True)\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam','lbfgs'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "\n",
    "# fit the model with the training set\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "\n",
      "\n",
      "0.623 (+/-0.045) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.600 (+/-0.044) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.626 (+/-0.021) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.633 (+/-0.055) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.588 (+/-0.040) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.619 (+/-0.031) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.609 (+/-0.083) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.591 (+/-0.042) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.609 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.623 (+/-0.032) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.580 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.610 (+/-0.046) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.637 (+/-0.024) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.577 (+/-0.002) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.627 (+/-0.034) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.650 (+/-0.029) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.527 (+/-0.144) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.629 (+/-0.024) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.616 (+/-0.029) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.591 (+/-0.039) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.627 (+/-0.018) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.612 (+/-0.050) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.610 (+/-0.071) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.622 (+/-0.048) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.633 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.597 (+/-0.046) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.619 (+/-0.018) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.594 (+/-0.085) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.594 (+/-0.024) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.633 (+/-0.046) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.637 (+/-0.038) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.577 (+/-0.002) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.606 (+/-0.050) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.630 (+/-0.020) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.554 (+/-0.186) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.603 (+/-0.032) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.643 (+/-0.018) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.629 (+/-0.049) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.640 (+/-0.064) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.640 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.599 (+/-0.061) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.636 (+/-0.022) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.652 (+/-0.056) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.577 (+/-0.072) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.623 (+/-0.041) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.635 (+/-0.035) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.632 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.622 (+/-0.021) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.658 (+/-0.010) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.626 (+/-0.020) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.614 (+/-0.042) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.643 (+/-0.026) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.630 (+/-0.014) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.610 (+/-0.016) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.620 (+/-0.038) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.626 (+/-0.016) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.617 (+/-0.014) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.643 (+/-0.032) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.630 (+/-0.028) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.635 (+/-0.064) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.630 (+/-0.020) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.586 (+/-0.128) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.616 (+/-0.034) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.653 (+/-0.024) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.623 (+/-0.066) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.626 (+/-0.027) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.645 (+/-0.013) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.604 (+/-0.019) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.614 (+/-0.016) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.642 (+/-0.001) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.545 (+/-0.175) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.613 (+/-0.040) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# Best paramete set\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "print('\\n')\n",
    "\n",
    "# All results\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.69       161\n",
      "           1       0.64      0.50      0.56       138\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       299\n",
      "   macro avg       0.64      0.63      0.63       299\n",
      "weighted avg       0.64      0.64      0.63       299\n",
      " \n",
      "\n",
      "------------------------------\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      " [[122  39]\n",
      " [ 69  69]]\n"
     ]
    }
   ],
   "source": [
    "# run prediction on the validation set \n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Classification report:\\n\\n', classification_report(y_test, y_pred), '\\n')\n",
    "print('------------------------------\\n')\n",
    "print('Confusion matrix:\\n\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.81959653\n",
      "Iteration 2, loss = 0.69784681\n",
      "Iteration 3, loss = 0.66083969\n",
      "Iteration 4, loss = 0.66063183\n",
      "Iteration 5, loss = 0.65095846\n",
      "Iteration 6, loss = 0.64445064\n",
      "Iteration 7, loss = 0.63962452\n",
      "Iteration 8, loss = 0.63597922\n",
      "Iteration 9, loss = 0.63081218\n",
      "Iteration 10, loss = 0.62609308\n",
      "Iteration 11, loss = 0.62341456\n",
      "Iteration 12, loss = 0.62094705\n",
      "Iteration 13, loss = 0.61544579\n",
      "Iteration 14, loss = 0.61348408\n",
      "Iteration 15, loss = 0.60921989\n",
      "Iteration 16, loss = 0.60627732\n",
      "Iteration 17, loss = 0.60332135\n",
      "Iteration 18, loss = 0.60182047\n",
      "Iteration 19, loss = 0.59705204\n",
      "Iteration 20, loss = 0.59474966\n",
      "Iteration 21, loss = 0.59114742\n",
      "Iteration 22, loss = 0.58832937\n",
      "Iteration 23, loss = 0.58528373\n",
      "Iteration 24, loss = 0.58290026\n",
      "Iteration 25, loss = 0.58033197\n",
      "Iteration 26, loss = 0.57792533\n",
      "Iteration 27, loss = 0.57494881\n",
      "Iteration 28, loss = 0.57268789\n",
      "Iteration 29, loss = 0.56914969\n",
      "Iteration 30, loss = 0.56704637\n",
      "Iteration 31, loss = 0.56452684\n",
      "Iteration 32, loss = 0.56353596\n",
      "Iteration 33, loss = 0.56031854\n",
      "Iteration 34, loss = 0.55964302\n",
      "Iteration 35, loss = 0.55722543\n",
      "Iteration 36, loss = 0.55230366\n",
      "Iteration 37, loss = 0.55042057\n",
      "Iteration 38, loss = 0.54823716\n",
      "Iteration 39, loss = 0.54764718\n",
      "Iteration 40, loss = 0.54577667\n",
      "Iteration 41, loss = 0.54243320\n",
      "Iteration 42, loss = 0.53982343\n",
      "Iteration 43, loss = 0.53833518\n",
      "Iteration 44, loss = 0.54133466\n",
      "Iteration 45, loss = 0.53227849\n",
      "Iteration 46, loss = 0.53147771\n",
      "Iteration 47, loss = 0.52898897\n",
      "Iteration 48, loss = 0.52690713\n",
      "Iteration 49, loss = 0.52399071\n",
      "Iteration 50, loss = 0.52170558\n",
      "Iteration 51, loss = 0.52038049\n",
      "Iteration 52, loss = 0.51888486\n",
      "Iteration 53, loss = 0.51585390\n",
      "Iteration 54, loss = 0.51402070\n",
      "Iteration 55, loss = 0.51172246\n",
      "Iteration 56, loss = 0.51250563\n",
      "Iteration 57, loss = 0.50799568\n",
      "Iteration 58, loss = 0.50743593\n",
      "Iteration 59, loss = 0.50440649\n",
      "Iteration 60, loss = 0.50235036\n",
      "Iteration 61, loss = 0.49957069\n",
      "Iteration 62, loss = 0.49769270\n",
      "Iteration 63, loss = 0.49615501\n",
      "Iteration 64, loss = 0.49493641\n",
      "Iteration 65, loss = 0.49151200\n",
      "Iteration 66, loss = 0.48999179\n",
      "Iteration 67, loss = 0.48784489\n",
      "Iteration 68, loss = 0.48685587\n",
      "Iteration 69, loss = 0.48449906\n",
      "Iteration 70, loss = 0.48364675\n",
      "Iteration 71, loss = 0.48140841\n",
      "Iteration 72, loss = 0.47814202\n",
      "Iteration 73, loss = 0.47619693\n",
      "Iteration 74, loss = 0.47571527\n",
      "Iteration 75, loss = 0.47256614\n",
      "Iteration 76, loss = 0.47561446\n",
      "Iteration 77, loss = 0.46904468\n",
      "Iteration 78, loss = 0.46669279\n",
      "Iteration 79, loss = 0.46473001\n",
      "Iteration 80, loss = 0.46203370\n",
      "Iteration 81, loss = 0.46037893\n",
      "Iteration 82, loss = 0.46046467\n",
      "Iteration 83, loss = 0.45731463\n",
      "Iteration 84, loss = 0.45571486\n",
      "Iteration 85, loss = 0.45402250\n",
      "Iteration 86, loss = 0.45087248\n",
      "Iteration 87, loss = 0.45302998\n",
      "Iteration 88, loss = 0.44718074\n",
      "Iteration 89, loss = 0.44964878\n",
      "Iteration 90, loss = 0.44375587\n",
      "Iteration 91, loss = 0.44361701\n",
      "Iteration 92, loss = 0.44026670\n",
      "Iteration 93, loss = 0.43971420\n",
      "Iteration 94, loss = 0.43703547\n",
      "Iteration 95, loss = 0.43358780\n",
      "Iteration 96, loss = 0.43287918\n",
      "Iteration 97, loss = 0.43052539\n",
      "Iteration 98, loss = 0.43077456\n",
      "Iteration 99, loss = 0.42632944\n",
      "Iteration 100, loss = 0.42438775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instanciate the MLP classifier\n",
    "mlp = MLPClassifier(max_iter=100,verbose=True,activation=\"relu\",alpha=0.0001,hidden_layer_sizes=(100,),learning_rate=\"constant\",solver=\"sgd\")\n",
    "\n",
    "parameter_space =  {}\n",
    "\n",
    "# fit the model with the training set\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集:  0.8460431654676259\n",
      "測試集:  0.6287625418060201\n"
     ]
    }
   ],
   "source": [
    "# 預測成功的比例\n",
    "print('訓練集: ',mlp.score(X_train,y_train))\n",
    "print('測試集: ',mlp.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_dataset.data, image_dataset.target, test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   12.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is: 0.6532374100719425\n",
      "best params are: {'n_neighbors': 2, 'weights': 'uniform'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 建立KNN模型\n",
    "knnModel = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "k_range = list(range(1,10))\n",
    "weight_options = ['uniform','distance']\n",
    "\n",
    "param_gridknn = dict(n_neighbors = k_range,\n",
    "                     weights = weight_options)\n",
    "\n",
    "gridKNN = GridSearchCV(knnModel,\n",
    "                       param_gridknn,\n",
    "                       cv=5,\n",
    "                       scoring='accuracy',\n",
    "                       verbose=1,\n",
    "                      n_jobs=-1)\n",
    "\n",
    "gridKNN.fit(X_train,y_train)\n",
    "print('best score is:',str(gridKNN.best_score_))\n",
    "print('best params are:',str(gridKNN.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集:  0.8863309352517985\n",
      "測試集:  0.6555183946488294\n"
     ]
    }
   ],
   "source": [
    "# 預測成功的比例\n",
    "print('訓練集: ',gridKNN.score(X_train,y_train))\n",
    "print('測試集: ',gridKNN.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.69       161\n",
      "           1       0.64      0.50      0.56       138\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       299\n",
      "   macro avg       0.64      0.63      0.63       299\n",
      "weighted avg       0.64      0.64      0.63       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Image Classification using scikit-learn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
